# 과대적합 / 과소적합

# Train / Validation set

# 모뎉체크포인트

# 이미지 데이터 전처리



# 원핫인코딩 ( one hot encoding )
```
    구분    봄  여름    가을    겨울
    봄	    1   0	    0	    0
    여름    0	1	    0	    0
    가을	0	0	    1	    0
    겨울	0	0	    0	    1

    [1, 0, 0, 0]
    [0, 1, 0, 0]
    [0, 0, 1, 0]
    [0, 0, 0, 1]
```

# 활성함수 ( activation function )
```
    함수의 종류
        선형함수의 종류   
            dense
        비선형 함수의 종류 ( 활성 함수 )
            relu, sigmoid, softmax

    참고
        텐서플로우 공식 도큐먼트
        https://www.tensorflow.org/api_docs/python/tf/keras/activations


    model = tf.keras.models.Sequential([
        tf.keras.layers.Flatten( input_shape=(28, 28)),
        tf.keras.layers.Dense(512),
        tf.keras.layers.ReLU(),
        tf.keras.layers.Dense(128),
        tf.keras.layers.ReLU(),
        tf.keras.layers.Dense(64),
        tf.keras.layers.ReLU(),
        tf.keras.layers.Dense(32),
        tf.keras.layers.ReLU(), 
        tf.keras.layers.Dense(10),
        tf.keras.layers.Softmax(), 
    ])

    model = tf.keras.models.Sequential([
        tf.keras.layers.Flatten( input_shape=(28, 28)),
        tf.keras.layers.Dense(512, activation='relu'),
        tf.keras.layers.Dense(256, activation='relu'),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dense(32, activation='relu'),
        tf.keras.layers.Dense(10, activation='softmax'),
    ])


    model = tf.keras.models.Sequential([
        tf.keras.layers.Flatten( input_shape=(28, 28)),
        tf.keras.layers.Dense(512, activation='relu'),
        tf.keras.layers.Dense(256, activation='relu'),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dense(32, activation='relu'),
        tf.keras.layers.Dense(10, activation='sigmoid'),
    ])    
```

# 분류 - 출력층 활성함수와 Loss 설정
```
    원핫인 경우     : categorical_crossentropy
    원핫이 아닌 경우 : sparse_categorical_crossentropy

    마지막 출력 층                      Loss
    Dense(1, activation='sigmoid')      loss='binary_crossentropy'
    Dense(2이상, activation='softmax')  loss='categorical_crossentropy'
                                        loss='sparse_categorical_crossentropy'

```

# relu  sigmoid 샘플
``` pytion 
    
    from IPython.display import Image
    import numpy as np
    import matplotlib.pyplot as plt

    # relu 함수
    def relu(x):
        return np.maximum(x, 0)

    x = np.linspace(-10, 10)
    y = relu(x)

    plt.figure(figsize=(10, 7))
    plt.plot(x, y)
    plt.title('ReLU activation function')
    plt.show()    

    # simoid 함수
    s(x) = 1 / 1 + e-z승


    def sigmoid(z):
        return  1/(1+np.exp(-z))

    plt.figure(figsize=(10, 7))

    x = np.arange(-10, 10)
    y = sigmoid(x)

    plt.plot(x, y)
    plt.show()    

    # softmax
    ∂(xj) = exj승 /  ∑exi승
    
    def softmax(a) :
        exp_a = np.exp(a)
        sum_exp_a = np.sum(exp_a)
        y = exp_a / sum_exp_a
        return y

    y = softmax(a)
    print('Class 별 확률 값 출력')
    print('===' * 10)
    for i in range(3):
        print('Class {} 의 확률: {:.3f}'.format(i, y[i]))
    print('===' * 10)
    print('Class 별 확률 값의 합: {:.1f}'.format(y.sum()))
```

# 실습
```python
    # step01  기본모듈 임포트 + 추가 모듈
    import numpy as np
    import matplotlib.pyplot as plt
    import tensorflow as tf             

    from tensorflow.keras.layers import Dense, Flatten
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.callbacks import ModelCheckpoint

    # step02 데이터 전처리 
    fashion_mnist = tf.keras.datasets.fashion_mnist
    (x_train, y_train), (x_valid, y_valid) = fashion_mnist.load_data()    

    # 값 확인 
    x_train_shape, x_valid_shape
    y_train_shape, y_valid_shape

    # 이미지 normalization  ( x 값에 대해서만 한다. )
    x_train.min(), x_train.max()       # 적용 전 최소 / 최대값 확인
    x_train = x_train / 255.0
    x_valid = x_valid / 255.0
    x_train.min(), x_train.max()      # 적용 후  최소 / 최대값 확인

    # 샘플 데이터 시각화   <= 시험시에는 필요 없음 
    fig, axes = plt.subplots(2, 5)
    fig.set_size_inches(10, 5)

    for i in range(10):
        axes[i//5, i%5].imshow(x_train[i], cmap='gray')
        axes[i//5, i%5].set_title(str(y_train[i]), fontsize=15)
        plt.setp( axes[i//5, i%5].get_xticklabels(), visible=False)
        plt.setp( axes[i//5, i%5].get_yticklabels(), visible=False)
        axes[i//5, i%5].axis('off')

    plt.tight_layout()
    plt.show()

    # 모델 정의
    model = Sequential([
        Flatten(input_shape=(28, 28)),
    
        # Dense Layer
        Dense(1024, activation='relu'),
        Dense(512, activation='relu'),
        Dense(256, activation='relu'),
        Dense(128, activation='relu'),
        Dense(64, activation='relu'),
    
        # Classification을 위한 Softmax 
        Dense(10, activation='softmax'),
    ])
    model.summary()

    # 컴파일
    optimizer는 가장 최적화가 잘되는 알고리즘인 'adam'을 사용합니다.
    loss설정
        출력층 activation이 sigmoid 인 경우: binary_crossentropy
        출력층 activation이 softmax 인 경우:
            원핫인코딩(O): categorical_crossentropy
            원핫인코딩(X): sparse_categorical_crossentropy)
    metrics를 'acc' 혹은 'accuracy'로 지정하면, 학습시 정확도를 모니터링 할 수 있습니다.

    원핫인코딩 체크방법
        y_train[0]
        print(tf.one_hot(y_train[0], 10))

    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc']) 

    # 모델 체크포인트 생성
    checkpoint_path = "my_checkpoint.ckpt"
    checkpoint = ModelCheckpoint(
        filepath=checkpoint_path, 
        save_weights_only=True, 
        save_best_only=True, 
        monitor='val_loss', 
        verbose=1
    )

    # 학습
    validation_data를 반드시 지정합니다.
    epochs을 적절하게 지정합니다.
    callbacks에 바로 위에서 만든 checkpoint를 지정합니다.
    
    학습이 완료된 후에는 반드시 load_weights를 해주어야 합니다.
    그렇지 않으면, 열심히 ModelCheckpoint를 만든 의미가 없습니다

    history = model.fit(
        x_train, y_train,
        validation_data=(x_valid, y_valid),
        epochs=20,
        callbacks=[checkpoint],
    )    
    model.load_weights(checkpoint_path)

    # 검증
    model.evaluate(x_valid, y_valid)

    # 학습 오차에 대한 시각화
    plt.figure(figsize=(12, 9))
    plt.plot(np.arange(1, 21), history.history['loss'])
    plt.plot(np.arange(1, 21), history.history['val_loss'])
    plt.title('Loss / Val Loss', fontsize=20)
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend(['loss', 'val_loss'], fontsize=15)
    plt.show()


    plt.figure(figsize=(12, 9))
    plt.plot(np.arange(1, 21), history.history['acc'])
    plt.plot(np.arange(1, 21), history.history['val_acc'])
    plt.title('Acc / Val Acc', fontsize=20)
    plt.xlabel('Epochs')
    plt.ylabel('Acc')
    plt.legend(['acc', 'val_acc'], fontsize=15)
    plt.show()


```